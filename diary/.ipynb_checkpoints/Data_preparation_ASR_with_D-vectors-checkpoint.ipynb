{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import paderbox as pb\n",
    "from paderbox.array import interval\n",
    "from padercontrib.database.fearless import Fearless\n",
    "from padertorch import Model\n",
    "from paderbox.transform import mfcc\n",
    "from paderbox.transform import stft,fbank\n",
    "import scipy\n",
    "import re\n",
    "import os\n",
    "import pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import padertorch as pt\n",
    "import padercontrib as pc\n",
    "import paderbox as pb\n",
    "\n",
    "from pathlib import Path\n",
    "from padertorch import Model\n",
    "from sacred import Experiment, commands\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from sacred.observers import FileStorageObserver\n",
    "from fearless.sad.eval_data import get_data_preparation\n",
    "from paderbox.io.new_subdir import get_new_subdir\n",
    "from paderbox.io import load_json, dump_json\n",
    "from pprint import pprint\n",
    "from padercontrib.database.chime5.database import activity_frequency_to_time\n",
    "from collections import Counter\n",
    "from padertorch.contrib.jensheit.eval_sad import get_tp_fp_tn_fn\n",
    "from padertorch.contrib.jensheit.eval_sad import smooth_vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "from typing import Type, Any, Callable, Union, List, Optional, cast\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvAngularPen(\n",
       "  size=ModelParameterSize(total_count=2508071, trainable_count=2508071, total_bytes=10032284, trainable_bytes=10032284)\n",
       "  (convlayers): PT_ConvNet(\n",
       "    size=ModelParameterSize(total_count=2491204, trainable_count=2491204, total_bytes=9964816, trainable_bytes=9964816)\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (drop_out): Dropout(p=0.5, inplace=False)\n",
       "    (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       "  (adms_loss): AngularPenaltySMLoss(\n",
       "    (fc): Linear(in_features=100, out_features=167, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = '/net/vol/saadmann/models/SID/2021-07-17-22-01-02'\n",
    "ckpt_name = 'ckpt_best_loss.pth'\n",
    "device = 0\n",
    "model_SID = Model.from_storage_dir(\n",
    "    exp_dir, consider_mpi=True, checkpoint_name=ckpt_name\n",
    ")\n",
    "model_SID.to(device)\n",
    "model_SID.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, output_layers, *args):\n",
    "        super().__init__(*args)\n",
    "        self.output_layers = output_layers\n",
    "        #print(self.output_layers)\n",
    "        self.selected_out = OrderedDict()\n",
    "        #PRETRAINED MODEL\n",
    "        self.pretrained = model_SID\n",
    "        self.fhooks = []\n",
    "\n",
    "        for i,l in enumerate(list(self.pretrained._modules.keys())):\n",
    "            if i in self.output_layers:\n",
    "                self.fhooks.append(getattr(self.pretrained,l).register_forward_hook(self.forward_hook(l)))\n",
    "    \n",
    "    def forward_hook(self,layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.selected_out[layer_name] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pretrained(x)\n",
    "        return out, self.selected_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fearless dataset\n",
    "Fearless = Fearless()\n",
    "FearlessData = Fearless.data\n",
    "devList=list(FearlessData['datasets']['Dev_segment'].items())\n",
    "trnList=list(FearlessData['datasets']['Train_segment'].items())\n",
    "evalList=list(FearlessData['datasets']['Eval_segment'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "devSegLst=[]\n",
    "trnSegLst=[]\n",
    "evalSegLst=[]\n",
    "for a,b in devList:\n",
    "    devSegLst.append(b)\n",
    "\n",
    "for a,b in trnList:\n",
    "    trnSegLst.append(b)\n",
    "    \n",
    "for a,b in evalList:\n",
    "    evalSegLst.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS=pd.DataFrame(devSegLst)\n",
    "dfT=pd.DataFrame(trnSegLst)\n",
    "dfE=pd.DataFrame(evalSegLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7658889fc7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset/speaker_vectors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset/speaker_vectors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset'"
     ]
    }
   ],
   "source": [
    "#create folders\n",
    "if not os.path.exists(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset\"):\n",
    "    os.mkdir(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset\")\n",
    "if not os.path.exists(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset/speaker_vectors\"):\n",
    "    os.mkdir(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/devset/speaker_vectors\")\n",
    "    \n",
    "if not os.path.exists(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/evalset\"):\n",
    "    os.mkdir(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/evalset\")\n",
    "if not os.path.exists(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/evalset/speaker_vectors\"):\n",
    "    os.mkdir(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/evalset/speaker_vectors\")\n",
    "    \n",
    "if not os.path.exists(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/trainset\"):\n",
    "    os.mkdir(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/trainset\")\n",
    "if not os.path.exists(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/trainset/speaker_vectors\"):\n",
    "    os.mkdir(\"/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data/trainset/speaker_vectors\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS['audio_id']=np.nan\n",
    "dfS['audio_idprefix']=np.nan\n",
    "dfS['transcription_len']=np.nan\n",
    "dfS['vector_path']=np.nan\n",
    "dfS['intersection_ids']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT['audio_id']=np.nan\n",
    "dfT['audio_idprefix']=np.nan\n",
    "dfT['transcription_len']=np.nan\n",
    "dfT['vector_path']= np.nan\n",
    "dfT['intersection_ids']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfE['audio_id']=np.nan\n",
    "dfE['audio_idprefix']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS['data_not_removed???']=np.nan\n",
    "dfT['data_not_removed???']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure common speakers in both set\n",
    "dfS_list = dfS.speaker_id.unique()\n",
    "dfT_list = dfT.speaker_id.unique()\n",
    "IDs = list(set(dfS_list) & set(dfT_list))\n",
    "intersection_set = sorted(IDs, key=lambda name:name.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfS)):\n",
    "    dfS.loc[i,'intersection_ids'] = dfS['speaker_id'][i] in intersection_set\n",
    "for j in range(len(dfT)):\n",
    "    dfT.loc[j,'intersection_ids'] = dfT['speaker_id'][j] in intersection_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35473/35473 [02:57<00:00, 199.66it/s]\n",
      "100%|██████████| 9203/9203 [00:18<00:00, 505.96it/s]\n"
     ]
    }
   ],
   "source": [
    "#for i in tqdm(range(len(evalSegLst))):\n",
    "#    dfE.loc[i,'audio_path']=dfE.loc[i,'audio_path']['observation']\n",
    "#    dfE.loc[i,'audio_id']=re.split(r\"[ /.]+\",dfE.iloc[i]['audio_path'])[8]\n",
    "#    dfE.loc[i,'audio_idprefix']=dfE.loc[i,'audio_id'].split('_')[0]\n",
    "    \n",
    "for i in tqdm(range(len(trnSegLst))):\n",
    "    dfT.loc[i,'audio_path']=dfT.loc[i,'audio_path']['observation']\n",
    "    dfT.loc[i,'audio_id']=re.split(r\"[ /.]+\",dfT.iloc[i]['audio_path'])[8]\n",
    "    dfT.loc[i,'audio_idprefix']=str(dfT.loc[i,'speaker_id'])+'-'+str(dfT.loc[i,'audio_id'])\n",
    "    dfT.loc[i, 'transcription']=dfT['transcription'][i].replace('[unk]', '') # replace [unk]\n",
    "    dfT.loc[i,'transcription_len']=len(dfT['transcription'][i].split())      # count the number of words\n",
    "    \n",
    "for i in tqdm(range(len(devSegLst))):\n",
    "    dfS.loc[i,'audio_path']=dfS.loc[i,'audio_path']['observation']\n",
    "    dfS.loc[i,'audio_id']=re.split(r\"[ /.]+\",dfS.iloc[i]['audio_path'])[8]\n",
    "    dfS.loc[i,'audio_idprefix']=str(dfS.loc[i,'speaker_id'])+'-'+str(dfS.loc[i,'audio_id'])\n",
    "    dfS.loc[i, 'transcription']=dfS['transcription'][i].replace('[unk]', '') # replace [unk]\n",
    "    dfS.loc[i,'transcription_len']= len(dfS['transcription'][i].split())     # count the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files are stored in /net/vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset\"):\n",
    "    os.mkdir(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset\")\n",
    "if not os.path.exists(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset/embedding_vectors\"):\n",
    "    os.mkdir(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset/embedding_vectors\")\n",
    "    \n",
    "#if not os.path.exists(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/evalset\"):\n",
    "#    os.mkdir(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/evalset\")\n",
    "#if not os.path.exists(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/evalset/embedding_vectors\"):\n",
    "#   os.mkdir(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/evalset/embedding_vectors\")\n",
    "    \n",
    "if not os.path.exists(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/trainset\"):\n",
    "    os.mkdir(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/trainset\")\n",
    "if not os.path.exists(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/trainset/embedding_vectors\"):\n",
    "    os.mkdir(\"/net/vol/saadmann/experiments/fearless/asr2/dump/raw/trainset/embedding_vectors\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Embedding vectors usinf SID model for trainsegment and devsegment datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS_filtered = dfS.drop(dfS[dfS.num_samples < 4000].index)\n",
    "dfS_filtered.reset_index(drop=True, inplace=True)\n",
    "dfT_filtered = dfT.drop(dfT[dfT.num_samples < 4000].index)\n",
    "dfT_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data modification after stage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devset\n",
    "#devset has 8462 datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_devset = pd.read_csv('/home/saadmann/saadImp/fearless/fearless/asr/Files_use_for_speakers/devset/utt2spk', sep = ' ', header = None, names=['ID_details', 'IDs' ])\n",
    "unique_devset_IDs_list = list(unique_devset['ID_details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset\n",
    "#trainset has 30978 datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_trainset = pd.read_csv('/home/saadmann/saadImp/fearless/fearless/asr/Files_use_for_speakers/trainset/utt2spk', sep = ' ', header = None, names=['ID_details', 'IDs' ])\n",
    "unique_trainset_IDs_list = list(unique_trainset['ID_details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS_filtered['data_not_removed???']=np.nan\n",
    "dfT_filtered['data_not_removed???']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfS_filtered)):\n",
    "    dfS_filtered.loc[i,'data_not_removed???'] = dfS_filtered['audio_idprefix'][i] in unique_devset_IDs_list\n",
    "for i in range(len(dfT_filtered)):\n",
    "    dfT_filtered.loc[i,'data_not_removed???'] = dfT_filtered['audio_idprefix'][i] in unique_trainset_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the removed data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS_filtered_two = dfS_filtered.drop(dfS_filtered[dfS_filtered['data_not_removed???'] == False].index)\n",
    "dfS_filtered_two.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfT_filtered_two = dfT_filtered.drop(dfT_filtered[dfT_filtered['data_not_removed???'] == False].index)\n",
    "dfT_filtered_two.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8462/8462 [00:03<00:00, 2592.96it/s]\n"
     ]
    }
   ],
   "source": [
    "#segment dataset\n",
    "#devsegment\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(dfS_filtered_two))):       \n",
    "    ids = dfS_filtered_two['audio_idprefix'][i]\n",
    "    extension = '.npy'\n",
    "    full_path = '/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset/embedding_vectors'+'/'+str(ids)+extension \n",
    "    dfS_filtered_two.loc[i,'vector_path']=full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30978/30978 [00:27<00:00, 1118.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#trainsegment\n",
    "\n",
    "for i in tqdm(range(len(dfT_filtered_two))):       \n",
    "    ids = dfT_filtered_two['audio_idprefix'][i]\n",
    "    extension = '.npy'\n",
    "    full_path = '/net/vol/saadmann/experiments/fearless/asr2/dump/raw/trainset/embedding_vectors'+'/'+str(ids)+extension \n",
    "    dfT_filtered_two.loc[i,'vector_path']=full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8462/8462 [02:02<00:00, 69.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#devsegment data\n",
    "os.chdir('/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset/embedding_vectors')\n",
    "with torch.no_grad():\n",
    "     for i in tqdm(range(len(dfS_filtered_two))):\n",
    "        sid_dict = dict()\n",
    "        fbank_data = []\n",
    "        padded_audio = []\n",
    "        audio_sam = AudioSegment.from_wav(dfS_filtered_two['audio_path'][i])\n",
    "        if audio_sam.duration_seconds < 4:\n",
    "            pad_ms = (4 - audio_sam.duration_seconds)*1000\n",
    "            silence = AudioSegment.silent(duration=pad_ms) # milliseconds of silence needed\n",
    "            padded = audio_sam + silence\n",
    "            \n",
    "        elif audio_sam.duration_seconds >= 4:\n",
    "            pad_ms = 0\n",
    "            audio_sam = audio_sam[0:4000]\n",
    "            silence = AudioSegment.silent(duration=pad_ms)\n",
    "            padded = audio_sam + silence        \n",
    "  \n",
    "        a = padded.get_array_of_samples()\n",
    "        b = np.array(a)\n",
    "        padded_audio.append(b)\n",
    "        \n",
    "        \n",
    "        f_banks = fbank(padded_audio, sample_rate=8000, window_length=400, stft_shift=160, number_of_filters=64,\n",
    "                        stft_size=512,lowest_frequency=0,highest_frequency=None, preemphasis_factor=0.97,\n",
    "                        window=scipy.signal.windows.hamming, denoise=False)\n",
    "        \n",
    "        fbank_data.append(f_banks)\n",
    "        float_fbank = np.float32(fbank_data)\n",
    "        float_fbank = np.squeeze(float_fbank,0)\n",
    "        float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "        float_fbank = torch.from_numpy(float_fbank).to(device)\n",
    "        sid_dict['features'] = (float_fbank)\n",
    "        sid_dict['features'] = sid_dict['features']\n",
    "        x = sid_dict\n",
    "        model = NewModel(output_layers = [7]).to(device)\n",
    "        out, _ = model(x)\n",
    "        ids = str(dfS_filtered_two['audio_idprefix'][i])\n",
    "        emb_vect = out['prediction'].cpu().detach().numpy().astype('float32')\n",
    "        np.save(ids, emb_vect)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>transcription</th>\n",
       "      <th>audio_id</th>\n",
       "      <th>audio_idprefix</th>\n",
       "      <th>transcription_len</th>\n",
       "      <th>vector_path</th>\n",
       "      <th>intersection_ids</th>\n",
       "      <th>data_not_removed???</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>37280</td>\n",
       "      <td>GNC1</td>\n",
       "      <td>ROG AND WED LIKE UH ZERO AND FOUR ONES</td>\n",
       "      <td>FS02_ASR_track2_dev_0001</td>\n",
       "      <td>GNC1-FS02_ASR_track2_dev_0001</td>\n",
       "      <td>9.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>56720</td>\n",
       "      <td>CAPCOM1</td>\n",
       "      <td>COLUMBIA THIS IS HOUSTON DID YOU COPY L O S A ...</td>\n",
       "      <td>FS02_ASR_track2_dev_0002</td>\n",
       "      <td>CAPCOM1-FS02_ASR_track2_dev_0002</td>\n",
       "      <td>17.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>49520</td>\n",
       "      <td>BUZZ</td>\n",
       "      <td>THE UH PANORAMA ILL BE TAKING IS ABOUT THIRTY ...</td>\n",
       "      <td>FS02_ASR_track2_dev_0003</td>\n",
       "      <td>BUZZ-FS02_ASR_track2_dev_0003</td>\n",
       "      <td>14.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>54880</td>\n",
       "      <td>GNC4</td>\n",
       "      <td>TEST WOULD BE CYCLING AT ONE COUNT PER FIVE SE...</td>\n",
       "      <td>FS02_ASR_track2_dev_0004</td>\n",
       "      <td>GNC4-FS02_ASR_track2_dev_0004</td>\n",
       "      <td>22.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>47120</td>\n",
       "      <td>RETRO1</td>\n",
       "      <td>DID UH  SOMETHING ABOUT P TWENTY DATA THAT TIM...</td>\n",
       "      <td>FS02_ASR_track2_dev_0005</td>\n",
       "      <td>RETRO1-FS02_ASR_track2_dev_0005</td>\n",
       "      <td>12.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8457</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>30720</td>\n",
       "      <td>CAPCOM1</td>\n",
       "      <td>I DIDNT SEE A CHANGE IN THE FLIGHT PLAN AT ABO...</td>\n",
       "      <td>FS02_ASR_track2_dev_9198</td>\n",
       "      <td>CAPCOM1-FS02_ASR_track2_dev_9198</td>\n",
       "      <td>14.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>4720</td>\n",
       "      <td>TIC2</td>\n",
       "      <td>WERE GO</td>\n",
       "      <td>FS02_ASR_track2_dev_9199</td>\n",
       "      <td>TIC2-FS02_ASR_track2_dev_9199</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8459</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>45600</td>\n",
       "      <td>BUZZ</td>\n",
       "      <td>ROGER AFTER UH THIS FIRST P FIFTY SEVEN YOU WA...</td>\n",
       "      <td>FS02_ASR_track2_dev_9200</td>\n",
       "      <td>BUZZ-FS02_ASR_track2_dev_9200</td>\n",
       "      <td>14.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8460</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>8400</td>\n",
       "      <td>SPAN1</td>\n",
       "      <td>CHARLIE LETS GO TO ONE</td>\n",
       "      <td>FS02_ASR_track2_dev_9202</td>\n",
       "      <td>SPAN1-FS02_ASR_track2_dev_9202</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8461</th>\n",
       "      <td>/net/db/fearless/Audio/Segments/ASR_track2/Dev...</td>\n",
       "      <td>23040</td>\n",
       "      <td>UNK</td>\n",
       "      <td>I THINK HE WILL BE</td>\n",
       "      <td>FS02_ASR_track2_dev_9203</td>\n",
       "      <td>UNK-FS02_ASR_track2_dev_9203</td>\n",
       "      <td>5.0</td>\n",
       "      <td>/net/vol/saadmann/experiments/fearless/asr2/du...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8462 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             audio_path  num_samples  \\\n",
       "0     /net/db/fearless/Audio/Segments/ASR_track2/Dev...        37280   \n",
       "1     /net/db/fearless/Audio/Segments/ASR_track2/Dev...        56720   \n",
       "2     /net/db/fearless/Audio/Segments/ASR_track2/Dev...        49520   \n",
       "3     /net/db/fearless/Audio/Segments/ASR_track2/Dev...        54880   \n",
       "4     /net/db/fearless/Audio/Segments/ASR_track2/Dev...        47120   \n",
       "...                                                 ...          ...   \n",
       "8457  /net/db/fearless/Audio/Segments/ASR_track2/Dev...        30720   \n",
       "8458  /net/db/fearless/Audio/Segments/ASR_track2/Dev...         4720   \n",
       "8459  /net/db/fearless/Audio/Segments/ASR_track2/Dev...        45600   \n",
       "8460  /net/db/fearless/Audio/Segments/ASR_track2/Dev...         8400   \n",
       "8461  /net/db/fearless/Audio/Segments/ASR_track2/Dev...        23040   \n",
       "\n",
       "     speaker_id                                      transcription  \\\n",
       "0          GNC1            ROG AND WED LIKE UH ZERO AND FOUR ONES    \n",
       "1       CAPCOM1  COLUMBIA THIS IS HOUSTON DID YOU COPY L O S A ...   \n",
       "2          BUZZ  THE UH PANORAMA ILL BE TAKING IS ABOUT THIRTY ...   \n",
       "3          GNC4  TEST WOULD BE CYCLING AT ONE COUNT PER FIVE SE...   \n",
       "4        RETRO1  DID UH  SOMETHING ABOUT P TWENTY DATA THAT TIM...   \n",
       "...         ...                                                ...   \n",
       "8457    CAPCOM1  I DIDNT SEE A CHANGE IN THE FLIGHT PLAN AT ABO...   \n",
       "8458       TIC2                                            WERE GO   \n",
       "8459       BUZZ  ROGER AFTER UH THIS FIRST P FIFTY SEVEN YOU WA...   \n",
       "8460      SPAN1                             CHARLIE LETS GO TO ONE   \n",
       "8461        UNK                                 I THINK HE WILL BE   \n",
       "\n",
       "                      audio_id                    audio_idprefix  \\\n",
       "0     FS02_ASR_track2_dev_0001     GNC1-FS02_ASR_track2_dev_0001   \n",
       "1     FS02_ASR_track2_dev_0002  CAPCOM1-FS02_ASR_track2_dev_0002   \n",
       "2     FS02_ASR_track2_dev_0003     BUZZ-FS02_ASR_track2_dev_0003   \n",
       "3     FS02_ASR_track2_dev_0004     GNC4-FS02_ASR_track2_dev_0004   \n",
       "4     FS02_ASR_track2_dev_0005   RETRO1-FS02_ASR_track2_dev_0005   \n",
       "...                        ...                               ...   \n",
       "8457  FS02_ASR_track2_dev_9198  CAPCOM1-FS02_ASR_track2_dev_9198   \n",
       "8458  FS02_ASR_track2_dev_9199     TIC2-FS02_ASR_track2_dev_9199   \n",
       "8459  FS02_ASR_track2_dev_9200     BUZZ-FS02_ASR_track2_dev_9200   \n",
       "8460  FS02_ASR_track2_dev_9202    SPAN1-FS02_ASR_track2_dev_9202   \n",
       "8461  FS02_ASR_track2_dev_9203      UNK-FS02_ASR_track2_dev_9203   \n",
       "\n",
       "      transcription_len                                        vector_path  \\\n",
       "0                   9.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "1                  17.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "2                  14.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "3                  22.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "4                  12.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "...                 ...                                                ...   \n",
       "8457               14.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "8458                2.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "8459               14.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "8460                5.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "8461                5.0  /net/vol/saadmann/experiments/fearless/asr2/du...   \n",
       "\n",
       "     intersection_ids data_not_removed???  \n",
       "0                True                True  \n",
       "1                True                True  \n",
       "2                True                True  \n",
       "3                True                True  \n",
       "4                True                True  \n",
       "...               ...                 ...  \n",
       "8457             True                True  \n",
       "8458             True                True  \n",
       "8459             True                True  \n",
       "8460             True                True  \n",
       "8461             True                True  \n",
       "\n",
       "[8462 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfS_filtered_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2514.3132  ,  -851.7124  ,   517.3438  ,   562.57355 ,\n",
       "         3923.7131  ,  -408.98175 , -1264.9745  ,  2613.7576  ,\n",
       "         1071.3124  ,   292.79898 ,  1842.2456  ,  -443.9231  ,\n",
       "         -292.10803 ,  -905.26086 ,  -969.675   , -1341.3545  ,\n",
       "        -3035.8877  , -1216.3412  , -1379.5632  ,  1605.9855  ,\n",
       "           66.1563  ,    85.38613 ,  2961.8503  , -3067.7727  ,\n",
       "          -21.288977, -1653.1787  ,    97.94363 ,   447.90543 ,\n",
       "         -482.36395 , -2920.3657  , -1240.8381  ,   943.6239  ,\n",
       "        -1335.5791  , -2179.6138  ,  -636.59155 ,  3780.973   ,\n",
       "         3408.9312  , -1705.1616  ,   405.8573  ,  -602.68835 ,\n",
       "         2074.562   ,   786.81396 ,  1920.5143  ,  -654.033   ,\n",
       "           92.95202 , -2059.2114  ,  1737.7546  ,  3647.514   ,\n",
       "         -491.00714 ,   613.46405 , -3063.3228  ,   213.17009 ,\n",
       "          210.25935 ,  2155.2583  , -3950.9534  ,  -172.34418 ,\n",
       "         -587.61395 ,   596.7047  , -2038.4171  , -2386.04    ,\n",
       "         2374.4312  ,  2885.016   , -2615.2566  ,   253.8099  ,\n",
       "         -860.53235 , -1029.2433  ,  -258.2531  ,   776.801   ,\n",
       "         -420.32724 ,  2122.0059  ,   -12.267753,  -138.36525 ,\n",
       "        -3303.3748  ,  -647.8064  , -2243.6084  ,  -435.24594 ,\n",
       "         1917.6099  ,  -904.7704  , -2346.6575  ,  1357.9531  ,\n",
       "        -2132.1926  ,  3474.664   ,  1168.8762  ,   134.83005 ,\n",
       "          847.2029  ,  3246.8638  ,  -105.36231 ,  1928.1543  ,\n",
       "         1164.9816  ,  4424.5386  ,   -74.772125, -1449.7574  ,\n",
       "         -462.82245 , -2198.8474  ,   762.819   ,  1237.1104  ,\n",
       "          141.32693 ,  1137.1785  ,   950.5966  ,  -284.17245 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset/embedding_vectors/GNC1-FS02_ASR_track2_dev_0001.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30978/30978 [05:17<00:00, 97.46it/s] \n"
     ]
    }
   ],
   "source": [
    "#trainset\n",
    "os.chdir('/net/vol/saadmann/experiments/fearless/asr2/dump/raw/trainset/embedding_vectors')\n",
    "with torch.no_grad():\n",
    "     for i in tqdm(range(len(dfT_filtered_two))):\n",
    "\n",
    "        sid_dict = dict()\n",
    "        fbank_data = []\n",
    "        padded_audio = []\n",
    "        audio_sam = AudioSegment.from_wav(dfT_filtered_two['audio_path'][i])\n",
    "        if audio_sam.duration_seconds < 4:\n",
    "            pad_ms = (4 - audio_sam.duration_seconds)*1000\n",
    "            silence = AudioSegment.silent(duration=pad_ms) # milliseconds of silence needed\n",
    "            padded = audio_sam + silence\n",
    "            \n",
    "        elif audio_sam.duration_seconds >= 4:\n",
    "            pad_ms = 0\n",
    "            audio_sam = audio_sam[0:4000]\n",
    "            silence = AudioSegment.silent(duration=pad_ms)\n",
    "            padded = audio_sam + silence        \n",
    "  \n",
    "        a = padded.get_array_of_samples()\n",
    "        b = np.array(a)\n",
    "        padded_audio.append(b)\n",
    "        \n",
    "        \n",
    "        f_banks = fbank(padded_audio, sample_rate=8000, window_length=400, stft_shift=160, number_of_filters=64,\n",
    "                        stft_size=512,lowest_frequency=0,highest_frequency=None, preemphasis_factor=0.97,\n",
    "                        window=scipy.signal.windows.hamming, denoise=False)\n",
    "\n",
    "        fbank_data.append(f_banks)\n",
    "        float_fbank = np.float32(fbank_data)\n",
    "        float_fbank = np.squeeze(float_fbank,0)\n",
    "        float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "        float_fbank = torch.from_numpy(float_fbank).to(device)\n",
    "        sid_dict['features'] = (float_fbank)\n",
    "        sid_dict['features'] = sid_dict['features']\n",
    "        x = sid_dict\n",
    "        model = NewModel(output_layers = [7]).to(device)\n",
    "        out, _ = model(x)\n",
    "        ids = str(dfT_filtered_two['audio_idprefix'][i])\n",
    "        emb_vect = out['prediction'].cpu().detach().numpy().astype('float32')\n",
    "        np.save(ids, emb_vect)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.47535781e+04, -1.07595205e+04,  6.98768408e+03,\n",
       "         4.66336035e+03,  5.33763633e+04, -6.42256738e+03,\n",
       "        -1.78867500e+04,  3.71358672e+04,  1.50528330e+04,\n",
       "         5.16365918e+03,  2.45950176e+04, -5.51115430e+03,\n",
       "        -4.08814209e+03, -1.32355957e+04, -1.24099062e+04,\n",
       "        -1.79957012e+04, -4.15006641e+04, -1.84729395e+04,\n",
       "        -1.63571143e+04,  2.56718320e+04,  1.62994824e+03,\n",
       "         1.87099585e+03,  3.97519961e+04, -4.22237969e+04,\n",
       "         4.61313080e+02, -2.31303652e+04,  1.68311188e+02,\n",
       "         7.06022754e+03, -4.49741162e+03, -4.12989297e+04,\n",
       "        -1.53729717e+04,  1.38782637e+04, -1.80510664e+04,\n",
       "        -3.05935723e+04, -7.02277246e+03,  5.33776953e+04,\n",
       "         4.65676406e+04, -2.38589863e+04,  6.20915381e+03,\n",
       "        -9.78052539e+03,  2.78424766e+04,  1.02733018e+04,\n",
       "         2.68680332e+04, -8.35006152e+03,  6.64330078e+02,\n",
       "        -2.96893613e+04,  2.49281895e+04,  5.29137578e+04,\n",
       "        -6.80055859e+03,  9.93752637e+03, -4.27445430e+04,\n",
       "         8.18188477e+02,  2.58522632e+03,  2.93165430e+04,\n",
       "        -5.26529453e+04, -1.78546301e+03, -9.33629785e+03,\n",
       "         9.51308984e+03, -2.87494844e+04, -3.51165742e+04,\n",
       "         3.29218711e+04,  3.85579219e+04, -3.74899727e+04,\n",
       "         2.88437866e+03, -1.16954336e+04, -1.40381543e+04,\n",
       "        -4.73638232e+03,  8.46661328e+03, -6.08654590e+03,\n",
       "         2.89759648e+04,  1.36347607e+03, -1.92709363e+03,\n",
       "        -4.60129492e+04, -9.77006152e+03, -3.15240938e+04,\n",
       "        -4.48095557e+03,  2.62004453e+04, -1.53049980e+04,\n",
       "        -3.12998809e+04,  1.88674004e+04, -3.10866133e+04,\n",
       "         4.82497578e+04,  1.75248223e+04,  4.59408545e+03,\n",
       "         1.22116221e+04,  4.40424219e+04, -2.90448456e+01,\n",
       "         2.90449590e+04,  1.68027734e+04,  5.89702148e+04,\n",
       "        -2.35500879e+03, -2.03085273e+04, -3.71020898e+03,\n",
       "        -3.07692402e+04,  1.12629795e+04,  1.72737305e+04,\n",
       "         2.99994824e+03,  1.59729922e+04,  1.42480742e+04,\n",
       "        -4.93452441e+03]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load('/net/vol/saadmann/experiments/fearless/asr2/dump/raw/devset/embedding_vectors/AFD1-FS02_ASR_track2_dev_0144.npy')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8695/8695 [00:03<00:00, 2858.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#segment dataset\n",
    "#devsegment\n",
    "\n",
    "for i in tqdm(range(len(dfS_filtered_two))):       \n",
    "    ids = dfS_filtered_two['audio_idprefix'][i]\n",
    "    extension = '.npy'\n",
    "    full_path = '/net/vol/bibash_01/experiments/fearless/asr2/dump/raw/devset/embedding_vectors'+'/'+str(ids)+extension \n",
    "    dfS_filtered_two.loc[i,'vector_path']=full_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33125/33125 [00:19<00:00, 1669.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#trainsegment\n",
    "\n",
    "for i in tqdm(range(len(dfT_filtered_two))):       \n",
    "    ids = dfT_filtered_two['audio_idprefix'][i]\n",
    "    extension = '.npy'\n",
    "    full_path = '/net/vol/bibash_01/experiments/fearless/asr2/dump/raw/trainset/embedding_vectors'+'/'+str(ids)+extension \n",
    "    dfT_filtered_two.loc[i,'vector_path']=full_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8695, 33125)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfS_filtered), len(dfT_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of data files\n",
    "\n",
    "def create_speaker_vector(dataF, pthMz):\n",
    "    curDir=os.getcwd()\n",
    "    chkDir='/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data'\n",
    "    updDir=chkDir + '/' + pthMz\n",
    "    os.chdir(updDir)\n",
    "    tempDf=dataF\n",
    "    if pthMz == 'devset' or pthMz == 'trainset':\n",
    "        with open(\"onehot.scp\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                if tempDf['intersection_ids'][i] == True:  \n",
    "                    x=tempDf.iloc[i]['audio_idprefix']+\"  \"+tempDf.iloc[i]['vector_path']\n",
    "                    f.write(x+'\\n')\n",
    "            f.close()\n",
    "        os.system('sort onehot.scp -o onehot.scp')\n",
    "    os.chdir(curDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wave_files(dataF,pthMz):\n",
    "    curDir=os.getcwd()\n",
    "    chkDir='/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data'\n",
    "    updDir=chkDir + '/' + pthMz\n",
    "    os.chdir(updDir)\n",
    "    tempDf=dataF\n",
    "    \n",
    "    if pthMz == 'devset' or pthMz == 'trainset':\n",
    "        with open(\"wav.scp\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                if tempDf['intersection_ids'][i] == True:  \n",
    "                    x=tempDf.iloc[i]['audio_idprefix']+\"  \"+tempDf.iloc[i]['audio_path']\n",
    "                    f.write(x+'\\n')\n",
    "            f.close()\n",
    "        os.system('sort wav.scp -o wav.scp')\n",
    "    if pthMz=='evalset':\n",
    "        with open(\"wav.scp\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):  \n",
    "                x=tempDf.iloc[i]['audio_id']+\"  \"+tempDf.iloc[i]['audio_path']\n",
    "                f.write(x+'\\n')\n",
    "            f.close() \n",
    "        os.system('sort wav.scp -o wav.scp')\n",
    "    os.chdir(curDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_files(dataF, pthMz):\n",
    "    curDir=os.getcwd()\n",
    "    chkDir='/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data'\n",
    "    updDir=chkDir + '/' + pthMz\n",
    "    os.chdir(updDir)\n",
    "    tempDf=dataF\n",
    "    \n",
    "    if pthMz == 'devset' or pthMz == 'trainset':\n",
    "        with open(\"text\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                if tempDf['intersection_ids'][i] == True:  \n",
    "                    x=tempDf.iloc[i]['audio_idprefix']+\"  \"+tempDf.iloc[i]['transcription']\n",
    "                    f.write(x+'\\n')\n",
    "            f.close()\n",
    "        os.system('sort text -o text')\n",
    "    os.chdir(curDir)\n",
    "    \n",
    "    if pthMz == 'evalset':\n",
    "        with open(\"text\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                x=tempDf.iloc[i]['audio_id']\n",
    "                f.write(x+'\\n')\n",
    "            f.close()\n",
    "    os.chdir(curDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creates_others_files(dataF, pthMz, intersection_set):\n",
    "    curDir=os.getcwd()\n",
    "    chkDir='/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/data'\n",
    "    updDir=chkDir + '/' + pthMz\n",
    "    os.chdir(updDir)\n",
    "    tempDf=dataF\n",
    "    \n",
    "    if pthMz == 'devset' or pthMz == 'trainset':\n",
    "        with open(\"text\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                if tempDf['intersection_ids'][i] == True:  \n",
    "                    x=tempDf.iloc[i]['audio_idprefix']+\"  \"+tempDf.iloc[i]['transcription']\n",
    "                    f.write(x+'\\n')\n",
    "            f.close()\n",
    "            os.system('sort text -o text')\n",
    "        with open(\"utt2spk\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                if tempDf['intersection_ids'][i] == True:  \n",
    "                    x=tempDf.iloc[i]['audio_idprefix']+\"  \"+tempDf.iloc[i]['speaker_id']\n",
    "                    f.write(x+'\\n')\n",
    "            f.close()\n",
    "            os.system('sort utt2spk -o utt2spk')\n",
    "        with open(\"spk2utt\",'w',encoding = 'utf-8') as f:\n",
    "            #testNames=tempDf['speaker_id'].unique()\n",
    "            testNames = intersection_set\n",
    "            for i in range(len(testNames)):\n",
    "                testList=str(list(tempDf[tempDf['speaker_id']==testNames[i]]['audio_idprefix'])).replace('[','').replace(']','').replace(',','').replace(\"'\",\"\")\n",
    "                testSpeaker=testNames[i]\n",
    "                testConcat=''\n",
    "                for j in range(len(testList)):\n",
    "                    testConcat += testList[j]\n",
    "                f.write(testSpeaker+' '+testConcat+'\\n')    \n",
    "            f.close()\n",
    "            os.system('sort spk2utt -o spk2utt')\n",
    "    os.chdir(curDir)\n",
    "    \n",
    "    if pthMz == 'evalset':\n",
    "        with open(\"utt2spk\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                x=tempDf.iloc[i]['audio_id']\n",
    "                f.write(x+'\\n')\n",
    "            f.close()\n",
    "        with open(\"spk2utt\",'w',encoding = 'utf-8') as f:\n",
    "            for i in range(len(tempDf)):\n",
    "                x=tempDf.iloc[i]['audio_id']\n",
    "                f.write(x+'\\n')\n",
    "            f.close()\n",
    "    os.chdir(curDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devset\n",
    "create_wave_files(dfS,'devset')\n",
    "create_text_files(dfS,'devset')\n",
    "creates_others_files(dfS,'devset', intersection_set)\n",
    "create_speaker_vector(dfS,'devset')\n",
    "\n",
    "\n",
    "# Trainset\n",
    "create_wave_files(dfT,'trainset')\n",
    "create_text_files(dfT,'trainset')\n",
    "creates_others_files(dfT,'trainset', intersection_set)\n",
    "create_speaker_vector(dfT,'trainset')\n",
    "\n",
    "#Eval Set\n",
    "creates_others_files(dfE,'evalset', intersection_set)\n",
    "create_speaker_vector(dfE, 'evalset')\n",
    "os.chdir('/home/bibash_01/my_project/espnet/egs2/fearlessData/asr1/') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2020",
   "language": "python",
   "name": "project_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

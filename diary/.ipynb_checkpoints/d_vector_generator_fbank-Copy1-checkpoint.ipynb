{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook generates d_vectors with the model '/net/vol/saadmann/models/SID/2021-07-17-22-01-02' which is trained with f_banks cascaded class for 100dim d_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "import scipy\n",
    "\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import padertorch as pt\n",
    "import padercontrib as pc\n",
    "import paderbox as pb\n",
    "from padertorch import Model\n",
    "from paderbox.array import interval\n",
    "from padercontrib.database.fearless import Fearless\n",
    "from padertorch import Model\n",
    "from paderbox.transform import mfcc\n",
    "from paderbox.transform import stft,fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_SID(\n",
       "  size=ModelParameterSize(total_count=5388634, trainable_count=5388634, total_bytes=21554536, trainable_bytes=21554536)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool2d): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "  (layer1): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=218, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = '/net/vol/dheerajpr/models/SID/2021-10-12-23-24-11'\n",
    "ckpt_name = 'ckpt_best_loss.pth'\n",
    "device = 0\n",
    "model_SID = Model.from_storage_dir(\n",
    "    exp_dir, consider_mpi=True, checkpoint_name=ckpt_name\n",
    ")\n",
    "model_SID.to(device)\n",
    "model_SID.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, output_layers, *args):\n",
    "        super().__init__(*args)\n",
    "        self.output_layers = output_layers\n",
    "        #print(self.output_layers)\n",
    "        self.selected_out = OrderedDict()\n",
    "        #PRETRAINED MODEL\n",
    "        self.pretrained = model_SID\n",
    "        self.fhooks = []\n",
    "\n",
    "        for i,l in enumerate(list(self.pretrained._modules.keys())):\n",
    "            if i in self.output_layers:\n",
    "                self.fhooks.append(getattr(self.pretrained,l).register_forward_hook(self.forward_hook(l)))\n",
    "    \n",
    "    def forward_hook(self,layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.selected_out[layer_name] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pretrained(x)\n",
    "        return out, self.selected_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padercontrib.database.fearless import Fearless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>transcription</th>\n",
       "      <th>vector_path</th>\n",
       "      <th>intersection_ids</th>\n",
       "      <th>d_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>70000</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>NO WAIT UNTIL AFTER LAUNCH AND WE GET TRANSMIT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>18880</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>[unk] A F D ON YOUR LOOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>10000</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>GO NETWORK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>27040</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>PROCEDURES A F D ON A F D CONFERENCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>19440</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>MOCR SYSTEMS ONE AND THREE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_path  num_samples speaker_id  \\\n",
       "0  {'observation': '/net/db/fearless/Audio/Segmen...        70000       AFD1   \n",
       "1  {'observation': '/net/db/fearless/Audio/Segmen...        18880       AFD1   \n",
       "2  {'observation': '/net/db/fearless/Audio/Segmen...        10000       AFD1   \n",
       "3  {'observation': '/net/db/fearless/Audio/Segmen...        27040       AFD1   \n",
       "4  {'observation': '/net/db/fearless/Audio/Segmen...        19440       AFD1   \n",
       "\n",
       "                                       transcription  vector_path  \\\n",
       "0  NO WAIT UNTIL AFTER LAUNCH AND WE GET TRANSMIT...          NaN   \n",
       "1                           [unk] A F D ON YOUR LOOP          NaN   \n",
       "2                                         GO NETWORK          NaN   \n",
       "3               PROCEDURES A F D ON A F D CONFERENCE          NaN   \n",
       "4                         MOCR SYSTEMS ONE AND THREE          NaN   \n",
       "\n",
       "  intersection_ids  d_vector  \n",
       "0             True       0.0  \n",
       "1             True       0.0  \n",
       "2             True       0.0  \n",
       "3             True       0.0  \n",
       "4             True       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FearlessData = Fearless.data\n",
    "devList=list(FearlessData['datasets']['Dev_segment'].items())\n",
    "devSegLst=[]\n",
    "for a,b in devList:\n",
    "    devSegLst.append(b)\n",
    "dfS = pd.DataFrame(devSegLst)\n",
    "\n",
    "dfS['vector_path']=np.nan\n",
    "dfS['intersection_ids']=np.nan\n",
    "dfS['d_vector']=np.nan\n",
    "\n",
    "np.nan_to_num(dfS['d_vector'], copy=False)\n",
    "\n",
    "\n",
    "intersection_set = load('intersection_set.npy')\n",
    "\n",
    "for i in range(len(dfS)):\n",
    "    dfS.loc[i,'intersection_ids'] = dfS['speaker_id'][i] in intersection_set\n",
    "dfS_filtered_2 = dfS[dfS['intersection_ids'] == True]\n",
    "dfS_filtered = dfS_filtered_2[dfS_filtered_2['num_samples'] > 4000]\n",
    "dfS_filtered_RI_sort_D = dfS_filtered.sort_values(by=['speaker_id'], ignore_index=True)\n",
    "dfS_filtered_RI_sort_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8479/8479 [03:21<00:00, 42.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#Dev-segment\n",
    "d_vec_dev_seg = torch.empty(1, 128).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(dfS_filtered_RI_sort_D))):\n",
    "        sid_dict = dict()\n",
    "        padded_audio = []\n",
    "        fbank_data = []\n",
    "        \"\"\" Obtain audio segments from the dataset\"\"\"\n",
    "        \"\"\" If segments smaller than 4secs, pad with silence. Else, extract 4secs from larger audio segments \"\"\"\n",
    "        audio = pb.io.load_audio(dfS_filtered_RI_sort_D['audio_path'][i]['observation'],dtype=np.int16)\n",
    "        if len(audio) < 32000:\n",
    "            pad = (32000 - len(audio))\n",
    "            padded = np.concatenate((audio,np.zeros(pad)))\n",
    "            \n",
    "        elif len(audio) >= 32000:\n",
    "            pad = 0\n",
    "            audio = audio[0:32000]\n",
    "            padded = audio     \n",
    "        \n",
    "        padded_audio.append(padded)\n",
    "        \"\"\" Compute the 64 dimensional filter banks for the 4secs fixed length audio segments\"\"\"\n",
    "    \n",
    "        fbank = pb.transform.fbank(padded, sample_rate=8000, window_length=400, stft_shift=160,number_of_filters=64,\n",
    "                        stft_size=512,lowest_frequency=0,highest_frequency=None, preemphasis_factor=0.97, \n",
    "                        window=scipy.signal.windows.hamming)\n",
    "        fbank_data.append(fbank)\n",
    "        float_fbank = np.float32(fbank_data)\n",
    "        float_fbank = np.squeeze(float_fbank,0)\n",
    "\n",
    "        float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "        float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "        float_fbank = torch.from_numpy(float_fbank).to(device)\n",
    "        sid_dict['features'] = (float_fbank)\n",
    "        sid_dict['features'] = sid_dict['features']\n",
    "#        model = NewModel(output_layers = [2][]).to(device)\n",
    "        x = sid_dict\n",
    "        model = NewModel(output_layers = [10]).to(device)\n",
    "        preds = model(x)\n",
    "#        preds[1]['fc1']\n",
    "\n",
    "        d_vec_dev_seg = torch.cat((d_vec_dev_seg, preds[1]['fc1']))\n",
    "    d_vec_dev_seg = d_vec_dev_seg[1:].type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_seg = asarray(d_vec_dev_seg)\n",
    "save('d_vector_dev_seg.npy', data_dev_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev-stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>end</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_speakers</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>start</th>\n",
       "      <th>transcription</th>\n",
       "      <th>example_id</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Stream...</td>\n",
       "      <td>[1716960, 1724240, 1738480, 1742720, 1967600, ...</td>\n",
       "      <td>14816000</td>\n",
       "      <td>8</td>\n",
       "      <td>[PROCEDURES1, FD1, PROCEDURES1, FD1, CONTROL1,...</td>\n",
       "      <td>[1710480, 1716960, 1724720, 1739440, 1955360, ...</td>\n",
       "      <td>[FLIGHT PROCEDURES., Go PROCEDURES., Upper clo...</td>\n",
       "      <td>FS02_dev_001</td>\n",
       "      <td>Dev_stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Stream...</td>\n",
       "      <td>[24800, 128560, 143040, 164080, 172320, 206240...</td>\n",
       "      <td>14400000</td>\n",
       "      <td>30</td>\n",
       "      <td>[EECOM3, TRACK0, MADRID, TRACK0, EECOM3, MADRI...</td>\n",
       "      <td>[16800, 123360, 140320, 148560, 164080, 176000...</td>\n",
       "      <td>[SPAN EECOM conference., MADRID TRACK., MADRID...</td>\n",
       "      <td>FS02_dev_002</td>\n",
       "      <td>Dev_stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Stream...</td>\n",
       "      <td>[98400, 158960, 169680, 262480, 526720, 767200...</td>\n",
       "      <td>14400000</td>\n",
       "      <td>26</td>\n",
       "      <td>[CAPCOM1, EMU, FD1, BUZZ, BUZZ, BUZZ, NEIL, BU...</td>\n",
       "      <td>[36320, 98400, 162720, 169680, 285840, 544480,...</td>\n",
       "      <td>[Uh roger BUZZ, and break break COLUMBIA this ...</td>\n",
       "      <td>FS02_dev_003</td>\n",
       "      <td>Dev_stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Stream...</td>\n",
       "      <td>[748080, 760480, 770000, 802720, 826080, 88120...</td>\n",
       "      <td>14955294</td>\n",
       "      <td>11</td>\n",
       "      <td>[RETRO1, FIDO1, RETRO1, UNK, FIDO1, RETRO1, FI...</td>\n",
       "      <td>[739600, 757520, 761920, 797040, 815840, 84056...</td>\n",
       "      <td>[FIDO this is RETRO., Go ahead., Did you get t...</td>\n",
       "      <td>FS02_dev_004</td>\n",
       "      <td>Dev_stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Stream...</td>\n",
       "      <td>[28240, 102000, 146320, 182160, 258720, 376480...</td>\n",
       "      <td>14400000</td>\n",
       "      <td>14</td>\n",
       "      <td>[CAPCOM1, BUZZ, CAPCOM1, BUZZ, CAPCOM1, BUZZ, ...</td>\n",
       "      <td>[0, 61920, 103840, 172560, 190080, 337840, 390...</td>\n",
       "      <td>[Is HOUSTON uh radio check and verify T.V. cir...</td>\n",
       "      <td>FS02_dev_005</td>\n",
       "      <td>Dev_stream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_path  \\\n",
       "0  {'observation': '/net/db/fearless/Audio/Stream...   \n",
       "1  {'observation': '/net/db/fearless/Audio/Stream...   \n",
       "2  {'observation': '/net/db/fearless/Audio/Stream...   \n",
       "3  {'observation': '/net/db/fearless/Audio/Stream...   \n",
       "4  {'observation': '/net/db/fearless/Audio/Stream...   \n",
       "\n",
       "                                                 end  num_samples  \\\n",
       "0  [1716960, 1724240, 1738480, 1742720, 1967600, ...     14816000   \n",
       "1  [24800, 128560, 143040, 164080, 172320, 206240...     14400000   \n",
       "2  [98400, 158960, 169680, 262480, 526720, 767200...     14400000   \n",
       "3  [748080, 760480, 770000, 802720, 826080, 88120...     14955294   \n",
       "4  [28240, 102000, 146320, 182160, 258720, 376480...     14400000   \n",
       "\n",
       "   num_speakers                                         speaker_id  \\\n",
       "0             8  [PROCEDURES1, FD1, PROCEDURES1, FD1, CONTROL1,...   \n",
       "1            30  [EECOM3, TRACK0, MADRID, TRACK0, EECOM3, MADRI...   \n",
       "2            26  [CAPCOM1, EMU, FD1, BUZZ, BUZZ, BUZZ, NEIL, BU...   \n",
       "3            11  [RETRO1, FIDO1, RETRO1, UNK, FIDO1, RETRO1, FI...   \n",
       "4            14  [CAPCOM1, BUZZ, CAPCOM1, BUZZ, CAPCOM1, BUZZ, ...   \n",
       "\n",
       "                                               start  \\\n",
       "0  [1710480, 1716960, 1724720, 1739440, 1955360, ...   \n",
       "1  [16800, 123360, 140320, 148560, 164080, 176000...   \n",
       "2  [36320, 98400, 162720, 169680, 285840, 544480,...   \n",
       "3  [739600, 757520, 761920, 797040, 815840, 84056...   \n",
       "4  [0, 61920, 103840, 172560, 190080, 337840, 390...   \n",
       "\n",
       "                                       transcription    example_id     dataset  \n",
       "0  [FLIGHT PROCEDURES., Go PROCEDURES., Upper clo...  FS02_dev_001  Dev_stream  \n",
       "1  [SPAN EECOM conference., MADRID TRACK., MADRID...  FS02_dev_002  Dev_stream  \n",
       "2  [Uh roger BUZZ, and break break COLUMBIA this ...  FS02_dev_003  Dev_stream  \n",
       "3  [FIDO this is RETRO., Go ahead., Did you get t...  FS02_dev_004  Dev_stream  \n",
       "4  [Is HOUSTON uh radio check and verify T.V. cir...  FS02_dev_005  Dev_stream  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Fearless()\n",
    "dataset_Dev_str = db.get_dataset('Dev_stream')\n",
    "df_Dev_str = pd.DataFrame(dataset_Dev_str)\n",
    "df_Dev_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:02<00:00, 30.61it/s]\n",
      "100%|██████████| 412/412 [00:11<00:00, 36.38it/s]\n",
      "100%|██████████| 239/239 [00:06<00:00, 35.04it/s]\n",
      "100%|██████████| 107/107 [00:03<00:00, 34.26it/s]\n",
      "100%|██████████| 259/259 [00:07<00:00, 34.85it/s]\n",
      "100%|██████████| 183/183 [00:05<00:00, 36.22it/s]\n",
      "100%|██████████| 270/270 [00:07<00:00, 34.89it/s]\n",
      "100%|██████████| 387/387 [00:10<00:00, 35.28it/s]\n",
      "100%|██████████| 574/574 [00:16<00:00, 35.72it/s]\n",
      "100%|██████████| 554/554 [00:15<00:00, 35.29it/s]\n",
      "100%|██████████| 385/385 [00:11<00:00, 34.62it/s]\n",
      "100%|██████████| 307/307 [00:09<00:00, 33.52it/s]\n",
      "100%|██████████| 570/570 [00:16<00:00, 34.41it/s]\n",
      "100%|██████████| 383/383 [00:11<00:00, 33.53it/s]\n",
      "100%|██████████| 446/446 [00:13<00:00, 33.03it/s]\n",
      "100%|██████████| 464/464 [00:14<00:00, 33.05it/s]\n",
      "100%|██████████| 178/178 [00:06<00:00, 29.51it/s]\n",
      "100%|██████████| 132/132 [00:04<00:00, 31.79it/s]\n",
      "100%|██████████| 98/98 [00:03<00:00, 31.37it/s]\n",
      "100%|██████████| 277/277 [00:08<00:00, 31.59it/s]\n",
      "100%|██████████| 446/446 [00:13<00:00, 32.26it/s]\n",
      "100%|██████████| 163/163 [00:05<00:00, 31.20it/s]\n",
      "100%|██████████| 139/139 [00:04<00:00, 31.06it/s]\n",
      "100%|██████████| 396/396 [00:12<00:00, 31.94it/s]\n",
      "100%|██████████| 443/443 [00:14<00:00, 31.54it/s]\n",
      "100%|██████████| 563/563 [00:17<00:00, 31.33it/s]\n",
      "100%|██████████| 60/60 [00:02<00:00, 28.52it/s]\n",
      "100%|██████████| 307/307 [00:10<00:00, 29.95it/s]\n",
      "100%|██████████| 315/315 [00:10<00:00, 30.00it/s]\n",
      "100%|██████████| 84/84 [00:02<00:00, 28.12it/s]\n"
     ]
    }
   ],
   "source": [
    "preds=[]\n",
    "d_vector_dev_str = torch.empty(1, 128).to(device)\n",
    "with torch.no_grad():\n",
    "    for i in range(len(df_Dev_str)):\n",
    "        for j in tqdm(range(len(df_Dev_str['start'][i]))):\n",
    "            #print(df_Dev_str['audio_path'][i]['observation'])\n",
    "            audio = pb.io.load_audio(df_Dev_str['audio_path'][i]['observation'],\n",
    "                             start =df_Dev_str['start'][i][j], stop = df_Dev_str['end'][i][j], dtype=np.int16)\n",
    "\n",
    "            sid_dict=dict()\n",
    "            fbank_data=[]\n",
    "            f_banks = pb.transform.fbank(audio, sample_rate=8000, window_length=400, stft_shift=180, number_of_filters=64,\n",
    "                        stft_size=512,lowest_frequency=0,highest_frequency=None, preemphasis_factor=0.97,\n",
    "                        window=scipy.signal.windows.hamming, denoise=False)\n",
    "\n",
    "            fbank_data.append(f_banks)\n",
    "            float_fbank = np.float32(fbank_data)\n",
    "            float_fbank = np.squeeze(float_fbank,0)\n",
    "            float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "            float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "            float_fbank = torch.from_numpy(float_fbank).to(device)\n",
    "            sid_dict['features'] = (float_fbank)\n",
    "            x = sid_dict\n",
    "            model = NewModel(output_layers = [10]).to(device)\n",
    "            preds = model(x)\n",
    "            \n",
    "            d_vector_dev_str = torch.cat((d_vector_dev_str, preds[1]['fc1']))\n",
    "        #d_vector_dev_str = d_vector_dev_str[1:].type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9203, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vector_dev_str[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_str = asarray(d_vector_dev_str[1:].cpu())\n",
    "save('d_vector_dev_str.npy', data_dev_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2020",
   "language": "python",
   "name": "project_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

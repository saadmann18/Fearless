{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import padertorch as pt\n",
    "import padercontrib as pc\n",
    "import paderbox as pb\n",
    "from padertorch import Model\n",
    "from paderbox.array import intervall\n",
    "from padercontrib.database.fearless import Fearless\n",
    "from padertorch import Model\n",
    "from paderbox.transform import mfcc\n",
    "from paderbox.transform import stft,fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>transcription</th>\n",
       "      <th>vector_path</th>\n",
       "      <th>intersection_ids</th>\n",
       "      <th>d_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>70000</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>NO WAIT UNTIL AFTER LAUNCH AND WE GET TRANSMIT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>18880</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>[unk] A F D ON YOUR LOOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>10000</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>GO NETWORK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>27040</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>PROCEDURES A F D ON A F D CONFERENCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'observation': '/net/db/fearless/Audio/Segmen...</td>\n",
       "      <td>19440</td>\n",
       "      <td>AFD1</td>\n",
       "      <td>MOCR SYSTEMS ONE AND THREE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_path  num_samples speaker_id  \\\n",
       "0  {'observation': '/net/db/fearless/Audio/Segmen...        70000       AFD1   \n",
       "1  {'observation': '/net/db/fearless/Audio/Segmen...        18880       AFD1   \n",
       "2  {'observation': '/net/db/fearless/Audio/Segmen...        10000       AFD1   \n",
       "3  {'observation': '/net/db/fearless/Audio/Segmen...        27040       AFD1   \n",
       "4  {'observation': '/net/db/fearless/Audio/Segmen...        19440       AFD1   \n",
       "\n",
       "                                       transcription  vector_path  \\\n",
       "0  NO WAIT UNTIL AFTER LAUNCH AND WE GET TRANSMIT...          NaN   \n",
       "1                           [unk] A F D ON YOUR LOOP          NaN   \n",
       "2                                         GO NETWORK          NaN   \n",
       "3               PROCEDURES A F D ON A F D CONFERENCE          NaN   \n",
       "4                         MOCR SYSTEMS ONE AND THREE          NaN   \n",
       "\n",
       "  intersection_ids  d_vector  \n",
       "0             True       0.0  \n",
       "1             True       0.0  \n",
       "2             True       0.0  \n",
       "3             True       0.0  \n",
       "4             True       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from padercontrib.database.fearless import Fearless\n",
    "Fearless = Fearless()\n",
    "FearlessData = Fearless.data\n",
    "devList=list(FearlessData['datasets']['Dev_segment'].items())\n",
    "#devList=list(FearlessData['datasets']['Dev_segment'].items())\n",
    "devSegLst=[]\n",
    "for a,b in devList:\n",
    "    devSegLst.append(b)\n",
    "dfS = pd.DataFrame(devSegLst)\n",
    "\n",
    "dfS['vector_path']=np.nan\n",
    "dfS['intersection_ids']=np.nan\n",
    "dfS['d_vector']=np.nan\n",
    "\n",
    "np.nan_to_num(dfS['d_vector'], copy=False)\n",
    "\n",
    "test_list = torch.tensor(dfS['d_vector'], dtype=torch.float)\n",
    "\n",
    "intersection_set = load('intersection_set.npy')\n",
    "\n",
    "for i in range(len(dfS)):\n",
    "    dfS.loc[i,'intersection_ids'] = dfS['speaker_id'][i] in intersection_set\n",
    "dfS_filtered_2 = dfS[dfS['intersection_ids'] == True]\n",
    "dfS_filtered = dfS_filtered_2[dfS_filtered_2['num_samples'] > 4000]\n",
    "dfS_filtered_RI_sort = dfS_filtered.sort_values(by=['speaker_id'], ignore_index=True)\n",
    "dfS_filtered_RI_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dfS_filtered_RI_sort['speaker_id'][:10]\n",
    "b = dfS_filtered_RI_sort['speaker_id'][18:28]\n",
    "c = dfS_filtered_RI_sort['speaker_id'][29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2fbdd1b4fa70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvec = np.load('d_vector_train_seg_fbank.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvec0 = dvec[0:10]\n",
    "dvec1 = dvec[18:28]\n",
    "\n",
    "dvec0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.98602312, 0.992681  , 0.99603263, 0.99865986, 0.9940386 ],\n",
       "        [0.99914289, 0.99985858, 0.9991107 , 0.99673304, 0.99971369],\n",
       "        [0.9989834 , 0.99963813, 0.99916072, 0.99684137, 0.9997727 ],\n",
       "        [0.99696769, 0.9995068 , 0.99997166, 0.99920254, 0.99975684],\n",
       "        [0.9962971 , 0.9991532 , 0.99981408, 0.99951051, 0.9993948 ]]),\n",
       " array([[0.99783311, 0.99699244, 0.99988115, 0.99941951, 0.99721631],\n",
       "        [0.99765332, 0.99847894, 0.98977447, 0.99501512, 0.99831665],\n",
       "        [0.99767741, 0.99852425, 0.99013541, 0.99518675, 0.99840137],\n",
       "        [0.99961076, 0.99988771, 0.99470019, 0.9982495 , 0.99984529],\n",
       "        [0.99984115, 0.99996286, 0.99547219, 0.9987497 , 0.99994042]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs1 = cs(dvec0[0:5],dvec0[5:10])\n",
    "cs2 = cs(dvec0[0:5],dvec1[0:5])\n",
    "cs1,cs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#167 dimensional d-vector from ang softmax output, 167 dimensional onehot ground-truth labels, roc curve, eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 dimensional d-vector from a layer before the output of ang softmax, \n",
    "#similarity between same speaker of train and dev dataset and assign label to dev d-vectors\n",
    "#compare between predicted assignment and groundtruth label of dev."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2020",
   "language": "python",
   "name": "project_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This notebook shows how to get d_vectors from sliced Dev_stream data using SAD outupts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This notebook shows how to get d_vectors from sliced Dev_stream data using SAD outupts\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import paderbox as pb\n",
    "from paderbox.array import interval\n",
    "from padercontrib.database.fearless import Fearless\n",
    "from padertorch import Model\n",
    "from paderbox.transform import mfcc\n",
    "from paderbox.transform import stft,fbank\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import padertorch as pt\n",
    "import padercontrib as pc\n",
    "import paderbox as pb\n",
    "\n",
    "from pathlib import Path\n",
    "from padertorch import Model\n",
    "from sacred import Experiment, commands\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from sacred.observers import FileStorageObserver\n",
    "from fearless.sad.eval_data import get_data_preparation\n",
    "from paderbox.io.new_subdir import get_new_subdir\n",
    "from paderbox.io import load_json, dump_json\n",
    "from pprint import pprint\n",
    "from padercontrib.database.chime5.database import activity_frequency_to_time\n",
    "from collections import Counter\n",
    "from padertorch.contrib.jensheit.eval_sad import get_tp_fp_tn_fn\n",
    "from padertorch.contrib.jensheit.eval_sad import smooth_vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "from typing import Type, Any, Callable, Union, List, Optional, cast\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/net/vol/saadmann/dump_audio_test/FS02_dev_001.wav'\n",
    "rre_audio = np.round(pb.io.load_audio(path)).astype(bool)\n",
    "rre_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrayInterval(\"1709760:1744880, 1952000:1969040, 2812480:2820720, 2827840:2994480, 2999040:3004400, 3016960:3021040, 3779840:3788400, 3794560:3846640, 4512000:4520560, 4532160:4590960, 4592800:4593520, 4768000:4803120, 6613120:6620240, 6623200:6624000, 6655200:6664240, 6664640:6726960, 6728800:6730480, 6734080:6790960, 6791200:6791920, 6793120:6900400, 6904320:6905200, 6905280:6946160, 7104000:7260880, 7635680:7644400, 7648000:7683120, 7744000:7744720, 7745280:7797840, 10959200:11012400, 11344160:11351760, 11371200:11400560, 12802560:12898320, 12985600:13065360, 13973440:13982480, 13983360:14019920\", shape=(14816000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals = interval.ArrayInterval(rre_audio)\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvAngularPen(\n",
       "  size=ModelParameterSize(total_count=2508071, trainable_count=2508071, total_bytes=10032284, trainable_bytes=10032284)\n",
       "  (convlayers): PT_ConvNet(\n",
       "    size=ModelParameterSize(total_count=2491204, trainable_count=2491204, total_bytes=9964816, trainable_bytes=9964816)\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (drop_out): Dropout(p=0.5, inplace=False)\n",
       "    (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       "  (adms_loss): AngularPenaltySMLoss(\n",
       "    (fc): Linear(in_features=100, out_features=167, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = '/net/vol/saadmann/models/SID/2021-07-17-22-01-02'\n",
    "ckpt_name = 'ckpt_best_loss.pth'\n",
    "device = 0\n",
    "model_SID = Model.from_storage_dir(\n",
    "    exp_dir, consider_mpi=True, checkpoint_name=ckpt_name\n",
    ")\n",
    "model_SID.to(device)\n",
    "model_SID.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, output_layers, *args):\n",
    "        super().__init__(*args)\n",
    "        self.output_layers = output_layers\n",
    "        #print(self.output_layers)\n",
    "        self.selected_out = OrderedDict()\n",
    "        #PRETRAINED MODEL\n",
    "        self.pretrained = model_SID\n",
    "        self.fhooks = []\n",
    "\n",
    "        for i,l in enumerate(list(self.pretrained._modules.keys())):\n",
    "            if i in self.output_layers:\n",
    "                self.fhooks.append(getattr(self.pretrained,l).register_forward_hook(self.forward_hook(l)))\n",
    "    \n",
    "    def forward_hook(self,layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.selected_out[layer_name] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pretrained(x)\n",
    "        return out, self.selected_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:05<00:00,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#Dev_stream 30 min audio sliced with SAD output.\n",
    "db = Fearless()\n",
    "dataset_Dev_str = db.get_dataset('Dev_stream')\n",
    "df_Dev_str = pd.DataFrame(dataset_Dev_str)\n",
    "d_vector_dev = torch.empty(1, 100).to(device)\n",
    "with torch.no_grad():\n",
    "    for j in tqdm(range(len(dataset_Dev_str))):\n",
    "        for i in range(len(intervals.intervals)):\n",
    "            if (intervals.intervals[i][1] - intervals.intervals[i][0]) > 4000:\n",
    "                #print('interval', i)\n",
    "                x_train_raw_audio = pb.io.load_audio(df_Dev_str['audio_path'][j]['observation'], \n",
    "                                                     start = intervals.intervals[i][0], stop = intervals.intervals[i][1])\n",
    "                sid_dict=dict()\n",
    "                fbank_data=[]\n",
    "\n",
    "                f_banks = fbank(x_train_raw_audio, sample_rate=8000, window_length=400, stft_shift=160, number_of_filters=64,\n",
    "                            stft_size=512,lowest_frequency=0,highest_frequency=None, preemphasis_factor=0.97,\n",
    "                            window=scipy.signal.windows.hamming, denoise=False)\n",
    "                fbank_data.append(f_banks)\n",
    "                float_fbank = np.float32(fbank_data)\n",
    "                float_fbank = np.squeeze(float_fbank,0)\n",
    "                float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "                float_fbank = np.expand_dims(float_fbank, axis=0)\n",
    "                float_fbank = torch.from_numpy(float_fbank).to(device)\n",
    "                sid_dict['features'] = (float_fbank)\n",
    "                sid_dict['features'] = sid_dict['features']\n",
    "                model = NewModel(output_layers = [7]).to(device)\n",
    "                x = sid_dict\n",
    "                out, _ = model(x)\n",
    "                d_vector_dev = torch.cat((d_vector_dev, out['prediction']))\n",
    "    d_vector_dev = d_vector_dev[1:].type(torch.DoubleTensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([840, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vector_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['prediction'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: d_vector generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2020",
   "language": "python",
   "name": "project_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
